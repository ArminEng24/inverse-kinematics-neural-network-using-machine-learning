{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: ANN Regression for robot arm control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor    # multilayer perceptron for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_kin_(joints, links, origin = [0, 0]):\n",
    "# implement the forward kinematics for a two joints planar manipulator\n",
    "# it's implemented externally so it can be used inside or outside the arm class\n",
    "    X = np.zeros(3)\n",
    "    Y = np.zeros(3)\n",
    "    X[0] = origin[0]\n",
    "    Y[0] = origin[1]\n",
    "    X[1] = X[0] + links[0] * np.cos(joints[0])\n",
    "    Y[1] = Y[0] + links[0] * np.sin(joints[0])\n",
    "    X[2] = X[1] + links[1] * np.cos(joints[0] + joints[1])\n",
    "    Y[2] = Y[1] + links[1] * np.sin(joints[0] + joints[1])\n",
    "    return [X, Y]   # return the coordinates of all link endpoints\n",
    "\n",
    "def deg2rad(degrees):\n",
    "# simple function for converting degrees to radiants\n",
    "    return degrees*np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arm():\n",
    "### the arm class contains all the methods for defining a two joints planar manipulator,\n",
    "### and implement a neural network inverse kinematics solver for it\n",
    "\n",
    "    def __init__(self, links = [10, 10], origin = [0, 0], init = [0, 0]):\n",
    "    # class contructor, defining the basic attributes of the arm and initial configuration\n",
    "        self.link1 = links[0]\n",
    "        self.link2 = links[1]\n",
    "        self.x0 = origin[0]\n",
    "        self.y0 = origin[1]\n",
    "        self.joint1 = init[0]\n",
    "        self.joint2 = init[1]\n",
    "        self.direct_kin()\n",
    "\n",
    "    def direct_kin(self):\n",
    "    # this forward kinematic function calculate the Cartesian coordinates for the current joint configuration    \n",
    "        [self.X, self.Y] = direct_kin_([self.joint1, self.joint2], [self.link1, self.link2], [self.x0, self.y0])\n",
    "\n",
    "    def plot_arm(self):\n",
    "    # 2D plot of the current arm configuration\n",
    "        plt.plot([-20,20],[0,0],'k')\n",
    "        plt.plot(self.X, self.Y, linewidth=2.0)\n",
    "        plt.plot(self.X, self.Y, 'ro', linewidth=2.0)\n",
    "        sum_links = (self.link1 + self.link2) * 1.1\n",
    "        plt.axis([-sum_links, sum_links, -1, sum_links])\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "    def create_data(self, ann, n_train, n_test, range1, range2):\n",
    "    # prepare the training and test sets for the neural network solver\n",
    "        self.inv_solver = ann\n",
    "        n_data = n_train + n_test\n",
    "        joint_space = np.hstack((np.random.uniform(range1[0], range1[1], size=(n_data, 1)), np.random.uniform(range2[0], range2[1], size=(n_data,1))))\n",
    "        cartesian_space = np.zeros(np.shape(joint_space))\n",
    "        for i in range(len(joint_space)):\n",
    "            ax, ay = direct_kin_(joint_space[i], [self.link1, self.link2])\n",
    "            cartesian_space[i] = [ax[2], ay[2]]\n",
    "        self.cart_train = np.asarray(cartesian_space[:n_train,:])\n",
    "        self.joint_train = np.asarray(joint_space[:n_train,:])\n",
    "        self.cart_test = np.asarray(cartesian_space[n_train:,:])\n",
    "        self.joint_test = np.asarray(joint_space[n_train:,:])\n",
    "            \n",
    "    def train_inv_kin(self):\n",
    "    # train the kinematic solver\n",
    "        self.inv_solver.fit(self.cart_train, self.joint_train)\n",
    "        score = self.inv_solver.score(self.cart_train, self.joint_train)\n",
    "        return(np.mean(score)) # return training accuracy\n",
    "\n",
    "    def test_inv_kin(self):\n",
    "    # test the kinematic solver\n",
    "        score = self.inv_solver.score(self.cart_test, self.joint_test)\n",
    "        return(np.mean(score)) # return testing accuracy\n",
    "\n",
    "    def inv_kin(self, Cartesian):\n",
    "    # query the trained inverse kinematic solver on a single Cartesian target\n",
    "        joints = self.inv_solver.predict([Cartesian])\n",
    "        [self.joint1, self.joint2] = joints[0]\n",
    "        self.direct_kin()\n",
    "        err = np.sqrt((Cartesian[0]-self.X[2])**2+(Cartesian[1]-self.Y[2])**2)\n",
    "        return(err, [self.X[2], self.Y[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1\n",
    "\n",
    "A. change the network structure (number of layers and neurons), and parameters (transfer functions, learning rate, algorithms, stop conditions): how does prediction accuracy change?\n",
    "\n",
    "B. change the quantity of training data, and the joint ranges: how does that affect accuracy?\n",
    "\n",
    "Perform systematic tests on appropriate values and ranges (how do you choose them?) and report your results, answering the questions.\n",
    "\n",
    "C.\tOptional: Extend the code so that the ANN for inverse kinematics is able to control a 3 joint robot arm moving in the 3D space. Add the 3rd joint and the z axis to the forward kinematics equations. Extend the ANN to 3 inputs and 3 outputs, train it and analyse the learning performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your submission below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.A: Network Structure and Parameter Variation Analysis (Changing Network Structure and Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this task, we explore how changing the neural network's structure (number of layers and neurons) and parameters (activation functions, learning rate, algorithms, stop conditions) affects prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the arm object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the arm object\n",
    "a = arm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists for different hyperparameters\n",
    "hidden_layer_sizes = [(100),(100,50)]\n",
    "activation_functions = ['relu', 'identity', 'tanh']\n",
    "learning_rates = ['constant', 'adaptive', 'invscaling']\n",
    "solvers = ['adam', 'lbfgs', 'sgd']\n",
    "max_iters = [500,1000]\n",
    "trial_list =[1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quantity of training data\n",
    "n_train = 1800\n",
    "n_test = 200\n",
    "\n",
    "# Joint ranges\n",
    "j1_range = (0, np.pi/2)\n",
    "j2_range = (0, np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Evaluation Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9597, Test Accuracy: 0.9616\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9669, Test Accuracy: 0.9632\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9762, Test Accuracy: 0.9719\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9683, Test Accuracy: 0.9609\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9713, Test Accuracy: 0.9709\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9667, Test Accuracy: 0.9697\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9735, Test Accuracy: 0.9681\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9755, Test Accuracy: 0.9817\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9748, Test Accuracy: 0.9696\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9635, Test Accuracy: 0.9569\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9791, Test Accuracy: 0.9765\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9460, Test Accuracy: 0.9466\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9802, Test Accuracy: 0.9809\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9740, Test Accuracy: 0.9755\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9526, Test Accuracy: 0.9413\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9776, Test Accuracy: 0.9817\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9786, Test Accuracy: 0.9729\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9714, Test Accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9895, Test Accuracy: 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9880, Test Accuracy: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9888, Test Accuracy: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9930, Test Accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9954, Test Accuracy: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9922, Test Accuracy: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9939, Test Accuracy: 0.9954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9915, Test Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9875, Test Accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9950, Test Accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9955, Test Accuracy: 0.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9939, Test Accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9896, Test Accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9851, Test Accuracy: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9886, Test Accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9960, Test Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9933, Test Accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9925, Test Accuracy: 0.9936\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9073, Test Accuracy: 0.9122\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9161, Test Accuracy: 0.9093\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9191, Test Accuracy: 0.9074\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9215, Test Accuracy: 0.9169\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9128, Test Accuracy: 0.9326\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9123, Test Accuracy: 0.9143\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9159, Test Accuracy: 0.9164\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9045, Test Accuracy: 0.8910\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9053, Test Accuracy: 0.8899\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9312, Test Accuracy: 0.9210\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.8935, Test Accuracy: 0.8785\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9229, Test Accuracy: 0.9302\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.1315, Test Accuracy: -0.0488\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.2105, Test Accuracy: -0.3848\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.1108, Test Accuracy: -0.3193\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.3024, Test Accuracy: -0.2960\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.3244, Test Accuracy: -0.3631\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2825, Test Accuracy: -0.3110\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6835, Test Accuracy: 0.7045\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6931, Test Accuracy: 0.7157\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6897, Test Accuracy: 0.6641\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6991, Test Accuracy: 0.7088\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6913, Test Accuracy: 0.6718\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6961, Test Accuracy: 0.7036\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.7018, Test Accuracy: 0.6749\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.7045, Test Accuracy: 0.7502\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.6964, Test Accuracy: 0.6964\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6899, Test Accuracy: 0.6590\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.7056, Test Accuracy: 0.6787\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.7032, Test Accuracy: 0.7173\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6978, Test Accuracy: 0.6707\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6861, Test Accuracy: 0.6529\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6917, Test Accuracy: 0.6683\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.7088, Test Accuracy: 0.6723\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6924, Test Accuracy: 0.6631\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6992, Test Accuracy: 0.7228\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6904, Test Accuracy: 0.6933\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7022, Test Accuracy: 0.6964\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7060, Test Accuracy: 0.6963\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6987, Test Accuracy: 0.7038\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7013, Test Accuracy: 0.6873\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6908, Test Accuracy: 0.7085\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7031, Test Accuracy: 0.7301\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6977, Test Accuracy: 0.7042\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6931, Test Accuracy: 0.7006\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6998, Test Accuracy: 0.6823\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7108, Test Accuracy: 0.6749\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7069, Test Accuracy: 0.6957\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7091, Test Accuracy: 0.7184\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7020, Test Accuracy: 0.6971\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6936, Test Accuracy: 0.6870\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7043, Test Accuracy: 0.6932\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6994, Test Accuracy: 0.6773\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7155, Test Accuracy: 0.6746\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7122, Test Accuracy: 0.7068\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6998, Test Accuracy: 0.7317\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6931, Test Accuracy: 0.6846\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.7036, Test Accuracy: 0.6999\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.7037, Test Accuracy: 0.7057\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6906, Test Accuracy: 0.7030\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6899, Test Accuracy: 0.7404\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7052, Test Accuracy: 0.7081\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6945, Test Accuracy: 0.7059\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6987, Test Accuracy: 0.6969\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.7075, Test Accuracy: 0.7101\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6896, Test Accuracy: 0.6999\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.1264, Test Accuracy: -0.1658\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.2500, Test Accuracy: -0.2205\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.3754, Test Accuracy: -0.3399\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2691, Test Accuracy: -0.4107\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2674, Test Accuracy: -0.3156\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.5139, Test Accuracy: -0.6950\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9622, Test Accuracy: 0.9635\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9685, Test Accuracy: 0.9557\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9684, Test Accuracy: 0.9608\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9629, Test Accuracy: 0.9555\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9577, Test Accuracy: 0.9661\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9604, Test Accuracy: 0.9470\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9641, Test Accuracy: 0.9616\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9578, Test Accuracy: 0.9394\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9629, Test Accuracy: 0.9672\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9570, Test Accuracy: 0.9469\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9617, Test Accuracy: 0.9586\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9625, Test Accuracy: 0.9698\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9662, Test Accuracy: 0.9571\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9646, Test Accuracy: 0.9623\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9601, Test Accuracy: 0.9575\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9669, Test Accuracy: 0.9627\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9644, Test Accuracy: 0.9554\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9683, Test Accuracy: 0.9616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9858, Test Accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9880, Test Accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9861, Test Accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9887, Test Accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9911, Test Accuracy: 0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9883, Test Accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9876, Test Accuracy: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9889, Test Accuracy: 0.9811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9860, Test Accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9882, Test Accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9907, Test Accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9904, Test Accuracy: 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9868, Test Accuracy: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9888, Test Accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9873, Test Accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9895, Test Accuracy: 0.9854\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9898, Test Accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9878, Test Accuracy: 0.9868\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9470, Test Accuracy: 0.9459\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9436, Test Accuracy: 0.9374\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9406, Test Accuracy: 0.9437\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9448, Test Accuracy: 0.9507\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9391, Test Accuracy: 0.9500\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9463, Test Accuracy: 0.9544\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9475, Test Accuracy: 0.9602\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9484, Test Accuracy: 0.9483\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9472, Test Accuracy: 0.9403\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9414, Test Accuracy: 0.9318\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9487, Test Accuracy: 0.9419\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9452, Test Accuracy: 0.9466\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.1178, Test Accuracy: 0.0470\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.1047, Test Accuracy: 0.0131\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.2068, Test Accuracy: 0.1667\n",
      "Trial Number : 1, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.1064, Test Accuracy: -0.0166\n",
      "Trial Number : 2, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.2814, Test Accuracy: 0.3544\n",
      "Trial Number : 3, Hidden Layers: 100, Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.0265, Test Accuracy: -0.0973\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9838, Test Accuracy: 0.9778\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9898, Test Accuracy: 0.9880\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9750, Test Accuracy: 0.9685\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9840, Test Accuracy: 0.9865\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9778, Test Accuracy: 0.9771\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9879, Test Accuracy: 0.9880\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9812, Test Accuracy: 0.9790\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9879, Test Accuracy: 0.9885\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9863, Test Accuracy: 0.9811\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9626, Test Accuracy: 0.9490\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9855, Test Accuracy: 0.9852\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9902, Test Accuracy: 0.9901\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9824, Test Accuracy: 0.9854\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9848, Test Accuracy: 0.9891\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9808, Test Accuracy: 0.9706\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9863, Test Accuracy: 0.9876\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9879, Test Accuracy: 0.9896\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9776, Test Accuracy: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9928, Test Accuracy: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9915, Test Accuracy: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9913, Test Accuracy: 0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9963, Test Accuracy: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9954, Test Accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9972, Test Accuracy: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9952, Test Accuracy: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9940, Test Accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9926, Test Accuracy: 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9963, Test Accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9910, Test Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9967, Test Accuracy: 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9945, Test Accuracy: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9952, Test Accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9933, Test Accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9963, Test Accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9962, Test Accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9956, Test Accuracy: 0.9964\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9336, Test Accuracy: 0.9478\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9156, Test Accuracy: 0.9186\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9559, Test Accuracy: 0.9543\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9513, Test Accuracy: 0.9541\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9334, Test Accuracy: 0.9279\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9415, Test Accuracy: 0.9302\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9483, Test Accuracy: 0.9407\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9496, Test Accuracy: 0.9462\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9613, Test Accuracy: 0.9567\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9527, Test Accuracy: 0.9461\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9554, Test Accuracy: 0.9627\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9453, Test Accuracy: 0.9380\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.0727, Test Accuracy: -0.1096\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.0404, Test Accuracy: -0.0765\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.3171, Test Accuracy: -0.3162\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2701, Test Accuracy: -0.2953\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2047, Test Accuracy: -0.6010\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: relu, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.2087, Test Accuracy: -0.0831\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6801, Test Accuracy: 0.6891\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6983, Test Accuracy: 0.6908\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.6922, Test Accuracy: 0.6907\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6882, Test Accuracy: 0.6783\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.7026, Test Accuracy: 0.6865\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6953, Test Accuracy: 0.6856\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.6921, Test Accuracy: 0.7084\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.6857, Test Accuracy: 0.6829\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.6902, Test Accuracy: 0.6586\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6978, Test Accuracy: 0.7194\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6846, Test Accuracy: 0.6867\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6894, Test Accuracy: 0.7039\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6890, Test Accuracy: 0.7275\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6914, Test Accuracy: 0.6769\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.6837, Test Accuracy: 0.7059\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6910, Test Accuracy: 0.6920\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6999, Test Accuracy: 0.6987\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.6562, Test Accuracy: 0.6590\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7008, Test Accuracy: 0.6858\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6983, Test Accuracy: 0.6966\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7145, Test Accuracy: 0.7035\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7052, Test Accuracy: 0.6618\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7032, Test Accuracy: 0.6848\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7035, Test Accuracy: 0.6773\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6902, Test Accuracy: 0.7069\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.7048, Test Accuracy: 0.6801\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6960, Test Accuracy: 0.6707\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6972, Test Accuracy: 0.7103\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7027, Test Accuracy: 0.7086\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6899, Test Accuracy: 0.6961\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6955, Test Accuracy: 0.6629\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6999, Test Accuracy: 0.6991\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.6980, Test Accuracy: 0.7334\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6972, Test Accuracy: 0.6795\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.6945, Test Accuracy: 0.7028\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.7122, Test Accuracy: 0.6896\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6809, Test Accuracy: 0.7086\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7018, Test Accuracy: 0.7193\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.6924, Test Accuracy: 0.6510\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6930, Test Accuracy: 0.6631\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6937, Test Accuracy: 0.6940\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6944, Test Accuracy: 0.7000\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7069, Test Accuracy: 0.6647\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7016, Test Accuracy: 0.7002\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.7005, Test Accuracy: 0.7272\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6945, Test Accuracy: 0.6937\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.6985, Test Accuracy: 0.7151\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.7009, Test Accuracy: 0.6999\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.1525, Test Accuracy: 0.1905\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.3083, Test Accuracy: 0.3093\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: -0.0332, Test Accuracy: -0.1809\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.1043, Test Accuracy: -0.2473\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.0812, Test Accuracy: 0.0714\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: identity, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.1808, Test Accuracy: 0.1183\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9790, Test Accuracy: 0.9765\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9826, Test Accuracy: 0.9860\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 500, Train Accuracy: 0.9765, Test Accuracy: 0.9776\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9817, Test Accuracy: 0.9810\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9807, Test Accuracy: 0.9884\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9750, Test Accuracy: 0.9634\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9815, Test Accuracy: 0.9793\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9769, Test Accuracy: 0.9698\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 500, Train Accuracy: 0.9746, Test Accuracy: 0.9744\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9785, Test Accuracy: 0.9736\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9790, Test Accuracy: 0.9733\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9786, Test Accuracy: 0.9722\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9748, Test Accuracy: 0.9785\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9785, Test Accuracy: 0.9823\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 500, Train Accuracy: 0.9727, Test Accuracy: 0.9807\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9816, Test Accuracy: 0.9809\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9828, Test Accuracy: 0.9874\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: adam, Max Iter: 1000, Train Accuracy: 0.9805, Test Accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9937, Test Accuracy: 0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9952, Test Accuracy: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9941, Test Accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9965, Test Accuracy: 0.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9975, Test Accuracy: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9967, Test Accuracy: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9950, Test Accuracy: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9952, Test Accuracy: 0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9957, Test Accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9965, Test Accuracy: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9968, Test Accuracy: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9982, Test Accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9944, Test Accuracy: 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9943, Test Accuracy: 0.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 500, Train Accuracy: 0.9956, Test Accuracy: 0.9954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9978, Test Accuracy: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9971, Test Accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: lbfgs, Max Iter: 1000, Train Accuracy: 0.9980, Test Accuracy: 0.9991\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9515, Test Accuracy: 0.9454\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9562, Test Accuracy: 0.9458\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9507, Test Accuracy: 0.9488\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9564, Test Accuracy: 0.9573\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9559, Test Accuracy: 0.9609\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: constant, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9531, Test Accuracy: 0.9683\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9563, Test Accuracy: 0.9550\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9605, Test Accuracy: 0.9597\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 500, Train Accuracy: 0.9523, Test Accuracy: 0.9550\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9455, Test Accuracy: 0.9565\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9466, Test Accuracy: 0.9494\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: adaptive, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.9554, Test Accuracy: 0.9592\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.3914, Test Accuracy: 0.3809\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.2305, Test Accuracy: 0.2803\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 500, Train Accuracy: 0.2511, Test Accuracy: 0.3048\n",
      "Trial Number : 1, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: -0.7925, Test Accuracy: -0.8919\n",
      "Trial Number : 2, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.3944, Test Accuracy: 0.3636\n",
      "Trial Number : 3, Hidden Layers: (100, 50), Activation: tanh, Learning Rate: invscaling, Solver: sgd, Max Iter: 1000, Train Accuracy: 0.2452, Test Accuracy: 0.3621\n"
     ]
    }
   ],
   "source": [
    "# Loop through each combination of hyperparameters and trials\n",
    "for hidden_size in hidden_layer_sizes:\n",
    "    for activation in activation_functions:\n",
    "        for solver in solvers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for max_iter in max_iters:\n",
    "                    for trial in trial_list:\n",
    "                        # Initialize MLPRegressor with current hyperparameters\n",
    "                        ann = MLPRegressor(hidden_layer_sizes=hidden_size, activation=activation,\n",
    "                                           solver=solver, learning_rate=learning_rate,\n",
    "                                           max_iter=max_iter, tol=1e-4)\n",
    "                        \n",
    "                        # Create training and testing data\n",
    "                        a.create_data(ann, n_train, n_test, j1_range, j2_range)\n",
    "                        \n",
    "                        # Train the inverse kinematics solver and evaluate its performance\n",
    "                        train_accuracy = a.train_inv_kin()\n",
    "                        test_accuracy = a.test_inv_kin()\n",
    "                        \n",
    "                        # Print the results for the current trial and hyperparameters\n",
    "                        print(f\"Trial Number : {trial}, Hidden Layers: {hidden_size}, Activation: {activation}, Learning Rate: {learning_rate}, \"\n",
    "                              f\"Solver: {solver}, Max Iter: {max_iter}, \"\n",
    "                              f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "By varying the network structure and parameters, we observe changes in prediction accuracy. This exploration helps us understand the impact of different configurations on the performance of the neural network-based inverse kinematics solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.B: Quantity of Training Data and Joint Range Impact Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists for different training data quantities and joint ranges are initialized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Data Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Lists\n",
    "n_trains = [1000, 2000, 5000]\n",
    "n_tests = [200, 500, 1000]\n",
    "j1_ranges = [(-np.pi/4, np.pi/2), (-np.pi/2, np.pi/2), (0, np.pi)]\n",
    "j2_ranges = [(-np.pi/4, np.pi/2), (-np.pi/2, np.pi/2), (0, np.pi)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8050, Test Accuracy: 0.7927\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6145, Test Accuracy: 0.5654\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9777, Test Accuracy: 0.9722\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.7369, Test Accuracy: 0.6475\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5434, Test Accuracy: 0.5289\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9897, Test Accuracy: 0.9839\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.7863, Test Accuracy: 0.7665\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5508, Test Accuracy: 0.4974\n",
      "Training Samples: 1000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9814, Test Accuracy: 0.9757\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.7900, Test Accuracy: 0.7987\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5183, Test Accuracy: 0.4790\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9680, Test Accuracy: 0.9675\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8095, Test Accuracy: 0.7921\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5366, Test Accuracy: 0.5220\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9823, Test Accuracy: 0.9817\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8228, Test Accuracy: 0.7999\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5861, Test Accuracy: 0.5567\n",
      "Training Samples: 1000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9838, Test Accuracy: 0.9778\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8085, Test Accuracy: 0.8034\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5043, Test Accuracy: 0.5197\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9853, Test Accuracy: 0.9821\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8062, Test Accuracy: 0.7879\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5317, Test Accuracy: 0.5133\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9763, Test Accuracy: 0.9764\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8162, Test Accuracy: 0.7907\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5791, Test Accuracy: 0.5580\n",
      "Training Samples: 1000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9768, Test Accuracy: 0.9767\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8037, Test Accuracy: 0.7914\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5850, Test Accuracy: 0.5558\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9903, Test Accuracy: 0.9881\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8021, Test Accuracy: 0.8246\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5794, Test Accuracy: 0.5455\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9917, Test Accuracy: 0.9939\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8111, Test Accuracy: 0.8054\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5568, Test Accuracy: 0.5057\n",
      "Training Samples: 2000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9901, Test Accuracy: 0.9875\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8119, Test Accuracy: 0.8022\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6218, Test Accuracy: 0.6000\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9900, Test Accuracy: 0.9903\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8199, Test Accuracy: 0.8212\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5891, Test Accuracy: 0.5542\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9878, Test Accuracy: 0.9825\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8126, Test Accuracy: 0.8133\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5975, Test Accuracy: 0.5885\n",
      "Training Samples: 2000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9902, Test Accuracy: 0.9871\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.7933, Test Accuracy: 0.8024\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6231, Test Accuracy: 0.6023\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9890, Test Accuracy: 0.9897\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8096, Test Accuracy: 0.7906\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5939, Test Accuracy: 0.5944\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9828, Test Accuracy: 0.9807\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8213, Test Accuracy: 0.7960\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5085, Test Accuracy: 0.5168\n",
      "Training Samples: 2000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9825, Test Accuracy: 0.9825\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.7926, Test Accuracy: 0.8342\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6172, Test Accuracy: 0.6336\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9944, Test Accuracy: 0.9933\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8259, Test Accuracy: 0.8091\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5939, Test Accuracy: 0.5794\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9947, Test Accuracy: 0.9968\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8126, Test Accuracy: 0.8395\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5905, Test Accuracy: 0.5778\n",
      "Training Samples: 5000, Test Samples: 200, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9931, Test Accuracy: 0.9913\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8126, Test Accuracy: 0.7814\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6218, Test Accuracy: 0.5968\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9933, Test Accuracy: 0.9935\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8179, Test Accuracy: 0.8257\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5890, Test Accuracy: 0.5667\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9921, Test Accuracy: 0.9921\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8011, Test Accuracy: 0.7877\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5949, Test Accuracy: 0.5928\n",
      "Training Samples: 5000, Test Samples: 500, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9944, Test Accuracy: 0.9925\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8101, Test Accuracy: 0.7891\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.6091, Test Accuracy: 0.6043\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-0.7853981633974483, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9941, Test Accuracy: 0.9946\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8079, Test Accuracy: 0.7984\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5994, Test Accuracy: 0.5856\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (-1.5707963267948966, 1.5707963267948966), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9935, Test Accuracy: 0.9939\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-0.7853981633974483, 1.5707963267948966), Train Accuracy: 0.8228, Test Accuracy: 0.8067\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (-1.5707963267948966, 1.5707963267948966), Train Accuracy: 0.5912, Test Accuracy: 0.5791\n",
      "Training Samples: 5000, Test Samples: 1000, Joint 1 Range: (0, 3.141592653589793), Joint 2 Range: (0, 3.141592653589793), Train Accuracy: 0.9934, Test Accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "for n_train in n_trains:\n",
    "    for n_test in n_tests:\n",
    "        for j1_range in j1_ranges:\n",
    "            for j2_range in j2_ranges:\n",
    "                # Initialize MLPRegressor with fixed hyperparameters\n",
    "                ann = MLPRegressor(hidden_layer_sizes=(100,50),\n",
    "                                   activation='relu', solver='adam', learning_rate='constant',\n",
    "                                   max_iter=2000, tol=1e-4)\n",
    "                \n",
    "                # Create training and testing data with current settings\n",
    "                a.create_data(ann, n_train, n_test, j1_range, j2_range)\n",
    "                \n",
    "                # Train the inverse kinematics solver and evaluate its performance\n",
    "                train_accuracy = a.train_inv_kin()\n",
    "                test_accuracy = a.test_inv_kin()\n",
    "                \n",
    "                # Print the results for the current configuration\n",
    "                print(f\"Training Samples: {n_train}, Test Samples: {n_test}, \"\n",
    "                      f\"Joint 1 Range: {j1_range}, Joint 2 Range: {j2_range}, \"\n",
    "                      f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.C: Extension to 3-Joint Robot Arm Control in 3D Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Forward Kinematics Function\n",
    "The forward kinematics function is modified to accommodate a three-joint spatial manipulator. It calculates the Cartesian coordinates of all link endpoints based on the joint angles and link lengths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_kin_(joints, links, origin = [0, 0, 0]):\n",
    "    # Implement the forward kinematics for a three-joint spatial manipulator\n",
    "    X = np.zeros(4)\n",
    "    Y = np.zeros(4)\n",
    "    Z = np.zeros(4)\n",
    "    X[0] = origin[0]\n",
    "    Y[0] = origin[1]\n",
    "    Z[0] = origin[2]\n",
    "    X[1] = X[0] + links[0] * np.cos(joints[0])\n",
    "    Y[1] = Y[0] + links[0] * np.sin(joints[0])\n",
    "    Z[1] = Z[0]\n",
    "    X[2] = X[1] + links[1] * np.cos(joints[0] + joints[1])\n",
    "    Y[2] = Y[1] + links[1] * np.sin(joints[0] + joints[1])\n",
    "    Z[2] = Z[1]\n",
    "    X[3] = X[2] + links[2] * np.cos(joints[0] + joints[1] + joints[2])\n",
    "    Y[3] = Y[2] + links[2] * np.sin(joints[0] + joints[1] + joints[2])\n",
    "    Z[3] = Z[2] + links[2] * np.sin(joints[2])\n",
    "    return [X, Y, Z]  # Return the coordinates of all link endpoints\n",
    "\n",
    "def deg2rad(degrees):\n",
    "    # Simple function for converting degrees to radians\n",
    "    return degrees * np.pi / 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Class Arm Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arm():\n",
    "    ### The arm class contains all the methods for defining a three-joint spatial manipulator,\n",
    "    ### and implement a neural network inverse kinematics solver for it\n",
    "\n",
    "    def __init__(self, links = [10, 10, 10], origin = [0, 0, 0], init = [0, 0, 0]):\n",
    "        # Class constructor, defining the basic attributes of the arm and initial configuration\n",
    "        self.link1 = links[0]\n",
    "        self.link2 = links[1]\n",
    "        self.link3 = links[2]\n",
    "        self.x0 = origin[0]\n",
    "        self.y0 = origin[1]\n",
    "        self.z0 = origin[2]\n",
    "        self.joint1 = init[0]\n",
    "        self.joint2 = init[1]\n",
    "        self.joint3 = init[2]\n",
    "        self.direct_kin()\n",
    "\n",
    "    def direct_kin(self):\n",
    "        # This forward kinematic function calculates the Cartesian coordinates for the current joint configuration\n",
    "        [self.X, self.Y, self.Z] = direct_kin_([self.joint1, self.joint2, self.joint3], [self.link1, self.link2, self.link3], [self.x0, self.y0, self.z0])\n",
    "\n",
    "    def create_data(self, ann, n_train, n_test, range1, range2, range3):\n",
    "        # Prepare the training and test sets for the neural network solver\n",
    "        self.inv_solver = ann\n",
    "        n_data = n_train + n_test\n",
    "        joint_space = np.hstack((np.random.uniform(range1[0], range1[1], size=(n_data, 1)),\n",
    "                                  np.random.uniform(range2[0], range2[1], size=(n_data, 1)),\n",
    "                                  np.random.uniform(range3[0], range3[1], size=(n_data, 1))))\n",
    "        cartesian_space = np.zeros(np.shape(joint_space))\n",
    "        for i in range(len(joint_space)):\n",
    "            ax, ay, az = direct_kin_(joint_space[i], [self.link1, self.link2, self.link3])\n",
    "            cartesian_space[i] = [ax[3], ay[3], az[3]]\n",
    "        self.cart_train = np.asarray(cartesian_space[:n_train, :])\n",
    "        self.joint_train = np.asarray(joint_space[:n_train, :])\n",
    "        self.cart_test = np.asarray(cartesian_space[n_train:, :])\n",
    "        self.joint_test = np.asarray(joint_space[n_train:, :])\n",
    "\n",
    "    def train_inv_kin(self):\n",
    "        # Train the kinematic solver\n",
    "        self.inv_solver.fit(self.cart_train, self.joint_train)\n",
    "        train_score = self.inv_solver.score(self.cart_train, self.joint_train)\n",
    "        print(f\"Training accuracy: {train_score:.4f}\")\n",
    "        return train_score\n",
    "\n",
    "    def test_inv_kin(self):\n",
    "        # Test the kinematic solver\n",
    "        test_score = self.inv_solver.score(self.cart_test, self.joint_test)\n",
    "        print(f\"Testing accuracy: {test_score:.4f}\")\n",
    "        return test_score\n",
    "\n",
    "    def inv_kin(self, Cartesian):\n",
    "        # Query the trained inverse kinematic solver for a single Cartesian target\n",
    "        joints = self.inv_solver.predict([Cartesian])\n",
    "        [self.joint1, self.joint2, self.joint3] = joints[0]\n",
    "        self.direct_kin()\n",
    "        err = np.sqrt((Cartesian[0] - self.X[3])**2 + (Cartesian[1] - self.Y[3])**2 + (Cartesian[2] - self.Z[3])**2)\n",
    "        return err, [self.X[3], self.Y[3], self.Z[3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9330\n",
      "Testing accuracy: 0.9440\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "arm_instance = arm(links=[10, 10, 10], origin=[0, 0, 0], init=[0, 0, 0])\n",
    "ann = MLPRegressor(hidden_layer_sizes=(200, 175, 150, 125, 100, 75, 50, 25), activation='relu', solver='adam',learning_rate='adaptive',learning_rate_init=0.0001, max_iter=1000)\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "j1_range = (0, np.pi/2)\n",
    "j2_range = (0, np.pi)\n",
    "j3_range = (0, np.pi/2)\n",
    "arm_instance.create_data(ann, n_train, n_test, j1_range, j2_range, j3_range)\n",
    "train_accuracy = arm_instance.train_inv_kin()\n",
    "test_accuracy = arm_instance.test_inv_kin()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
